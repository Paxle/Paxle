<?xml version="1.0" encoding="iso-8859-1"?>
<feed version="0.3"
  xmlns="http://purl.org/atom/ns#"
  xmlns:dc="http://purl.org/dc/elements/1.1/"
  xml:lang="eng">
  <title>VirtualBlog</title>
  <link rel="alternate" type="text/html" href="http://virtualdub.org/blog/index.php"/>
  <modified>2008-09-15T01:54:32-04:00</modified>
  <author>
    <name>lafiel</name>
    <url>http://virtualdub.org/blog/index.php</url>
    <email>pivot@virtualdub.org</email>
  </author>
  <tagline>Life as the author of VirtualDub</tagline>
  <id>tag:virtualduborg,2008:virtualblog</id>
  <generator url="http://www.pivotlog.net" version="Pivot+-+1.15%3A+%27Soundwave%27">Pivot</generator>
  <copyright>Copyright (c) 2008, Authors of VirtualBlog</copyright>
<entry>
    <title>Software pixel shader emulation in Windows Presentation Foundation (WPF)</title>
    <link rel="alternate" type="text/html" href="http://virtualdub.org/blog/pivot/entry.php?id=224"/>
    <modified>2008-09-15T01:45:00-04:00</modified>
    <issued>2008-09-15T01:45:00-04:00</issued>
    <id>tag:virtualduborg,2008:virtualblog.224</id>

    <created>2008-09-15T01:45:00-04:00</created>
    <summary type="text/plain">Windows Presentation Foundation (WPF) gained an interesting feature in .NET Framework 3.5 SP1, which is the ability to execute pixel shader effects in software via a just-in-time (JIT) compiler. Issues with introducing features in service packs aside, this is a cool addition, since it allows the same pixel shader code to run on the GPU and the CPU with reasonable performance on the latter. It's certainly better than the old effects system, which only supported software mode and required you to write a custom routine in a separate DLL instead.
Of course, being a sort of graphics guy but not a .NET kind of person, I had to dig into the shader jitter....</summary>
    <dc:subject>Software pixel shader emulation in Windows Presentation Foundation (WPF)</dc:subject>
		<author>
		 <name>phaeron</name>
	  </author>
	  <content type="text/html" mode="escaped" xml:lang="en" xml:base="http://virtualdub.org/blog/pivot/entry.php?id=224"><![CDATA[ <p>Windows Presentation Foundation (WPF) gained an interesting feature in .NET Framework 3.5 SP1, which is the ability to execute pixel shader effects in software via a just-in-time (JIT) compiler. Issues with introducing features in service packs aside, this is a cool addition, since it allows the same pixel shader code to run on the GPU and the CPU with reasonable performance on the latter. It's certainly better than the old effects system, which only supported software mode and required you to write a custom routine in a separate DLL instead.</p>
<p>Of course, being a sort of graphics guy but not a .NET kind of person, I had to dig into the shader jitter....</p><p><strong>Interface</strong></p>
<p>The way you use a custom shader effect in WPF is via the System.Windows.Media.Effects namespace, deriving from ShaderEffect and attaching a PixelShader object to it. You attach a precompiled pixel shader to the PixelShader and then attach the ShaderEffect to a UI element. There are facilities for binding properties to samplers and float constants.</p>
<p>You can't get to the vertex shader, so you can't take advantage of the hardware interpolators and all precomputation will have to be done in C#. Samplers can be switched between point and bilinear sampling, but there are no mipmaps and no support for wrapping.</p>
<p>WPF allows you to select three modes for the pixel shader, Auto, HardwareOnly, and SoftwareOnly. When SoftwareOnly is used, WPF converts the pixel shader to SSE2-based code using just-in-time (JIT) compilation, which is what we're interested in here.</p>
<p>The documentation doesn't give a lot of direction or note gotchas and could use a lot of improvement, but I could say that about a lot of the .NET Framework docs. When I originally looked at the jitter I was stuck without the docs and had to wing it via Intellisense, but I when I got access to the docs again I was surprised to find that the docs still weren't a lot of help. There's a lot more useful information on <a href="http://blogs.msdn.com/greg_schechter/archive/2008/05/09/a-series-on-gpu-based-effects-for-wpf.aspx">Greg Schechter's blog</a> about how to write custom ShaderEffects.</p>
<p><strong>Validation</strong></p>
<p>WPF does do some validation on the pixel shader, and will reject many shaders that are otherwise valid pixel shaders, even if you are running in hardware accelerated mode. First, your shader must use the vanilla ps_2_0 shader model – ps_1_1, ps_1_4, ps_2_a, ps_2_sw, and ps_3_0 will all be rejected. Second, attempting to use some features that aren't supported by WPF will also be caught and rejected, such as reading from color interpolators (v0).</p>
<p>What you can do, however, is cheat somewhat by compiling to the ps_2_a, ps_2_b, or ps_2_sw targets and then hack the version token to ps_2_0 (FFFF0200). You won't get away with trying to use gradients or predication, but arbitrary swizzle does work. That makes sense, since arbitrary swizzles are easy to do in jitted code, and there isn't any special encoding in shader bytecode for extended swizzles vs. standard ps2.0 swizzles. Doing this also allows you to exceed the standard ps_2_0 limits. I take no responsibility if you do this and your code breaks with a future WPF update, though.</p>
<p><strong>Code generation</strong></p>
<p>The jitter requires SSE2. It probably could have been implemented with SSE1+MMX, but the performance probably would have been mediocre, the fastest chips in that range being Athlon XPs. If you're experienced with writing vectorized image processing code, you'll beat the jitter handily, but otherwise, it doesn't do a bad job. I did all experimentation on an SSE4.1-capable CPU, but didn't see any instructions used beyond SSE2 profile.</p>
<p>All pixel arithmetic is done in single precision using SSE. This may be a bit slower than could be done with fixed-point, but at least there are no precision or range surprises. One gotcha is that this means NaNs can also appear, which you may not be used to if you have a shader model 2 level ATI card.</p>
<p>The jitter reorganizes shaders into structures of arrays (SOA) form and executes pixel shaders for four pixels in parallel. This means that a single SSE register holds one component of a register across four pixels. For instance, xmm0 might hold r0.x for pixels 0-3, and a dp3 instruction would look like this:</p>
<p>mulps xmm0, xmm3<br  />mulps xmm1, xmm4<br  />mulps xmm2, xmm5<br  />addps xmm0, xmm1<br  />addps xmm0, xmm2</p>
<p>SOA form avoids a lot of swizzle traffic that would result from cross-component operations like a dot product, since SSE is poor at horizontal data traffic and doesn't have free swizzles or write masks like pixel shaders do. The downsides are much greater register pressure, particularly due to constant bloating, and more complex execution for non-naturally vector operations like table lookups. Pixel shader hardware does this too in a way, but the hardware does 2x2 quads, whereas the jitter does 4x1. The hardware needs to do quads in order to compute mipmapping parameters and gradients, but the jitter never deals with mipmapped textures.</p>
<p>Surprisingly, complex scalar operations are expanded inline: sincos turns into a series of muls and adds, and log is also emitted inline (although it is quite expensive). This is different from the Direct3D PSGP, which calls out to CRT transcendental functions instead when compiling vertex shaders.</p>
<p>There isn't a lot of optimization done on the shaders. If you manage to get four rcps in a row, they'll all get coded even if they cancel out. Ordinarily this isn't too much of a problem, since the HLSL compiler will do a lot of optimization for you. It does mean there are some cases that only the jitter can optimize and that it misses, such as a vector multiply where two out of three components are multiplied by constant zero. The jitter will strip dead stores and remove redundant moves, though.</p>
<p>Texture sampling is very slow, as the jitter generates several pages of machine code for every texld instruction. I'm not kidding about this – here's the generated code for just one pixel out of a 4x1 block:</p>
<blockquote dir="ltr" style="MARGIN-RIGHT: 0px"><pre>lea         ebx,[edi+1] <br  />mov         ecx,dword ptr [esp+70h] <br  />mov         edx,dword ptr [esp+74h] <br  />movd        xmm2,ecx <br  />movaps      xmmword ptr [esp+100h],xmm2 <br  />movd        xmm3,edx <br  />movaps      xmmword ptr [esp+130h],xmm3 <br  />mov         edx,dword ptr [esp+17Ch] <br  />mov         esi,dword ptr [esp+78h] <br  />lea         ecx,[eax+1] <br  />movd        xmm4,esi <br  />movaps      xmmword ptr [esp+160h],xmm4 <br  />shl         edx,2 <br  />mov         esi,dword ptr [esp+38h]<br  />mov         dword ptr [esp+190h],esi <br  />mov         esi,dword ptr [esp+178h] <br  />imul        eax,edx <br  />imul        ecx,edx <br  />mov         edx,dword ptr [esp+178h] <br  />lea         edx,[edx+eax] <br  />lea         esi,[esi+eax] <br  />mov         eax,dword ptr [esp+178h] <br  />movd        xmm5,dword ptr [edx+edi*4] <br  />movd        xmm6,dword ptr [esi+ebx*4] <br  />mov         esi,dword ptr [esp+178h] <br  />lea         esi,[esi+ecx] <br  />lea         eax,[eax+ecx] <br  />movd        xmm7,dword ptr [esi+edi*4] <br  />movd        xmm0,dword ptr [eax+ebx*4] <br  />punpcklbw   xmm5,xmm5 <br  />punpcklbw   xmm6,xmm6 <br  />punpcklbw   xmm7,xmm7 <br  />punpcklbw   xmm0,xmm0 <br  />punpcklwd   xmm5,xmm5 <br  />punpcklwd   xmm6,xmm6 <br  />punpcklwd   xmm7,xmm7 <br  />punpcklwd   xmm0,xmm0 <br  />psrld       xmm5,18h <br  />psrld       xmm6,18h <br  />psrld       xmm7,18h <br  />psrld       xmm0,18h <br  />cvtdq2ps    xmm5,xmm5 <br  />cvtdq2ps    xmm6,xmm6 <br  />cvtdq2ps    xmm7,xmm7 <br  />cvtdq2ps    xmm0,xmm0 <br  />mov         eax,dword ptr [esp+48h]<br  />mov         ebx,dword ptr [esp+58h]<br  />mov         ecx,dword ptr [esp+68h]<br  />movd        xmm1,dword ptr [esp+190h] <br  />movd        xmm4,eax <br  />pshufd      xmm1,xmm1,0 <br  />pshufd      xmm4,xmm4,0 <br  />movd        xmm3,ebx <br  />movd        xmm2,ecx <br  />pshufd      xmm3,xmm3,0 <br  />pshufd      xmm2,xmm2,0 <br  />mulps       xmm0,xmm1 <br  />mulps       xmm7,xmm3 <br  />mulps       xmm1,xmm6 <br  />movaps      xmm6,xmmword ptr [esp+130h] <br  />addps       xmm7,xmm0 <br  />mulps       xmm3,xmm5 <br  />movaps      xmm5,xmmword ptr [esp+100h] <br  />mulps       xmm4,xmm7 <br  />movaps      xmm7,xmmword ptr [esp+160h] <br  />addps       xmm3,xmm1 <br  />shufps      xmm5,xmm5,93h <br  />mulps       xmm2,xmm3 <br  />shufps      xmm6,xmm6,93h <br  />addps       xmm2,xmm4 <br  />movaps      xmmword ptr [esp+80h],xmm2 <br  />shufps      xmm7,xmm7,93h <br  />mov         edx,dword ptr [esp+80h] <br  />mov         esi,dword ptr [esp+84h] <br  />movd        xmm0,edx <br  />movd        xmm1,esi <br  />mov         esi,dword ptr [esp+17Ch] <br  />addps       xmm5,xmm0 <br  />movaps      xmmword ptr [esp+0F0h],xmm5 <br  />addps       xmm6,xmm1 <br  />movaps      xmmword ptr [esp+120h],xmm6 <br  />mov         edi,dword ptr [esp+88h] <br  />mov         eax,dword ptr [esp+14h] <br  />movd        xmm2,edi <br  />mov         ebx,dword ptr [esp+24h] <br  />addps       xmm7,xmm2 <br  />movaps      xmmword ptr [esp+150h],xmm7 </pre></blockquote>
<p>Now imagine that included four times for every texld instruction in your shader.</p>
<p>Needless to say, this bloats the generated code very quickly, and it's not unusual to see a compiled pixel shader exceed 4K. Have you read the SIGGRAPH paper on Larrabee, where they explained that texture sampling couldn't be done efficiently on the main core? Well, here's an example. Part of this is due to SSE2's poor support for expanding byte components into floats and all of the data conversions needed to get coordinates and subtexel offsets to the right places, but there are also some optimization issues in this specific implementation. The most glaring one is the use of DIVPS to divide the components by 255 after bilinear filtering -- about twenty times slower than multiplication by inverse. The generated code also does runtime branching based on whether a sampler has bilinear filtering enabled, and computes a*(1-f) + b for linear interpolation when a + (b-a)*f probably would be faster. I didn't see any optimization for non-dependent texture fetches, so there's no major advantage to avoiding dependent reads – not that you could optimize them out much without access to the vertex shader anyway. One implication of all of this is that in some cases you may be better off using more ALU ops rather than a texture loop, even though the texture lookup would be much faster on the GPU.</p>
<p>The output section is the other slow part of the generated code. As I said above, the code works on 4x1 blocks, so it has to handle the oddballs at the end. Unfortunately, it does so by storing the vector and then copying each pixel with scalar ops and a branch check, so it incurs store forwarding stalls and is a bit slower than it could be:</p>
<blockquote dir="ltr" style="MARGIN-RIGHT: 0px"><pre>movdqa      xmmword ptr [esp-40h],xmm6 <br  />test        esi,esi <br  />mov         edi,dword ptr [esp-40h] <br  />mov         dword ptr [edx],edi <br  />je          047501A3 <br  />mov         eax,dword ptr [esp-3Ch] <br  />lea         esi,[esi-1] <br  />mov         dword ptr [edx+4],eax <br  />test        esi,esi <br  />je          047501B5 <br  />mov         ebx,dword ptr [esp-38h] <br  />lea         esi,[esi-1] <br  />mov         dword ptr [edx+8],ebx <br  />test        esi,esi <br  />je          047501C7 <br  />mov         ecx,dword ptr [esp-34h] <br  />lea         esi,[esi-1] <br  />mov         dword ptr [edx+0Ch],ecx </pre></blockquote>
<p>I would have liked to see a straight 4x loop with a vector store followed by fixup code instead. The difference won't be noticeable for long shaders, but you might notice it on a very short one, such as if you're using the effect to generate an image instead of transforming one.</p>
<p>Overall, the performance of the generated code is decent for ALU operations, but there's significant loop overhead and texture sampling is slow, so you want to avoid multipassing as much as possible. I will say that the overhead of the rest of WPF seems to be a much bigger problem than the jitted code; I did see some major slowdowns in the &lt;10 fps range once I tried more complicated shaders, but a lot of the slowness was due to what looked like a slow alpha blend routine in wpfgfx_0300.dll and a lot of wasteful per-frame allocation, which caused the GC heap size to skyrocket. I don't care if I do have 2GB of memory – it's obnoxious for a simple app displaying an image to jump up to 1.5GB and start swapping things out just because I resized the window.</p>
<p><strong>Bugs</strong></p>
<p>Overall, the shader jitter in WPF is a lot more robust than I had expected.</p>
<p>One of the first mistakes I made was to use sampler s0 without binding anything to it. This works fine in hardware – probably by chance – but it drove me nuts when I was trying to test the software mode and couldn't figure out why no sampler was bound. The software engine also returns the wrong value for an unbound sampler, giving a dull red when the color components should be all zero.</p>
<p>The rsq instruction is supposed to have no more than 1/2^-22 error, but the jitter compiles it to an RSQRTPS instruction, which only guarantees 1/2^-12 error. This means that expressions involving sqrt(), rsqrt(), and length() may be a bit sketchy in precision. The same goes for rcp, though I've heard modern CPUs actually compute it to much higher precision.</p>
<p>There are some funny little issues in the generated code, such as this fragment from a texld instruction:</p>
<p>maxps       xmm5,xmm4 <br  />maxps       xmm6,xmm4 <br  />maxps       xmm5,xmm4 <br  />maxps       xmm6,xmm4 </p>
<p>I couldn't think of why you'd need to do this, even with NaN behavior involved (minps/maxps are asymmetric with respect to specials). I initially suspected that this was a blown texture clamp and that two minps instructions were missing, but I couldn't get it to blow up with negative texture coordinates.</p>
<p><strong>Conclusion</strong></p>
<p>The WPF pixel shader jitter is actually fairly robust and performant, and should reliably support just about any shader that works in hardware mode. I believe it's currently the closest you can get to high-performance vectorized code purely from C#. My main complaint is that it's in WPF – this is technology that I would have liked to see in a core API somewhere in DirectX or Windows, rather than in the .NET Framework.</p> ]]></content>
  </entry>
<entry>
    <title>0.5 != 128/255</title>
    <link rel="alternate" type="text/html" href="http://virtualdub.org/blog/pivot/entry.php?id=223"/>
    <modified>2008-09-02T03:19:00-04:00</modified>
    <issued>2008-09-02T03:19:00-04:00</issued>
    <id>tag:virtualduborg,2008:virtualblog.223</id>

    <created>2008-09-02T03:19:00-04:00</created>
    <summary type="text/plain">I cringe whenever I see people implement YCbCr to RGB conversion like this:

y = 1.164 * (y - 16.0 / 256.0);r = y + 1.596 * (cr - 0.5);g = y - 0.813 * (cr - 0.5)&amp;nbsp;- 0.391 * (cb - 0.5);b = y + 2.018 * (cb - 0.5);
What's wrong with this, you say? Too slow?&amp;nbsp;No, that's not the problem. The problem is that the bias constants are wrong. The minor error is the 16/256 luma bias, which should be 16/255. That's a 0.02% error over the full range, so we can grudgingly let that slide. What isn't as excusable&amp;nbsp;are the 0.5 chroma bias constants. If you're working with 8-bit channels, the chroma center is placed at 128, which when converted to float is 128/255 rather than exactly one-half. This is an error of 0.5/255, which would also be barely excusable, except for one problem. The coefficients for converting chroma red and chroma blue are greater than 1 in magnitude, so they'll actually amplify the error. If you're converting from 8-bit YCbCr to 8-bit RGB, this basically guarantees that you'll frequently be off by one in one or more components. Even more fun is that the green channel errors won't coincide with the red and blue errors and will be in the opposite direction, which then leads to ugliness like blacks that aren't black and have color to them.
In other words, please use 16/255 and 128/255 when those are actually where your luma and chroma values are based.
(I have to confess that the reason this came to mind is that I found this issue in some prototype code of mine when I started actually hacking it into shape. Needless to say, the production code doesn't have this problem.)
You might be thinking that it's a bit weird to be doing a conversion on 8-bit components with floating point, and you'd be correct. The place where this frequently comes up is in 3D pixel shaders. A pixel shader is a natural place to do color conversion, and is also where you'd frequently encounter 8-bit components converted to floating point.&amp;nbsp;Unlike a CPU-based converter,&amp;nbsp;however, there is basically no extra cost to using the correct constants. The only time you'd be better off using 0.5 in a shader instead of 128/255 is if you're on a GeForce 3, in which case (a) you're already skating on thin ice precision-wise and (b) the hardware is 9-bit signed fixed point&amp;nbsp;so you're going to get 128/255 anyway. Otherwise, it's kind of sloppy to be displaying 720p video on-screen with a shader that doesn't get colors right just because someone was too lazy to type in the right constants.</summary>
    <dc:subject>0.5 != 128/255</dc:subject>
		<author>
		 <name>phaeron</name>
	  </author>
	  <content type="text/html" mode="escaped" xml:lang="en" xml:base="http://virtualdub.org/blog/pivot/entry.php?id=223"><![CDATA[ <p>I cringe whenever I see people implement YCbCr to RGB conversion like this:</p>
<blockquote dir="ltr" style="MARGIN-RIGHT: 0px">
<p>y = 1.164 * (y - 16.0 / 256.0);<br  />r = y + 1.596 * (cr - 0.5);<br  />g = y - 0.813 * (cr - 0.5) - 0.391 * (cb - 0.5);<br  />b = y + 2.018 * (cb - 0.5);</p></blockquote>
<p>What's wrong with this, you say? Too slow? No, that's not the problem. The problem is that the bias constants are wrong. The minor error is the 16/256 luma bias, which should be 16/255. That's a 0.02% error over the full range, so we can grudgingly let that slide. What isn't as excusable are the 0.5 chroma bias constants. If you're working with 8-bit channels, the chroma center is placed at 128, which when converted to float is 128/255 rather than exactly one-half. This is an error of 0.5/255, which would also be barely excusable, except for one problem. The coefficients for converting chroma red and chroma blue are greater than 1 in magnitude, so they'll actually amplify the error. If you're converting from 8-bit YCbCr to 8-bit RGB, this basically guarantees that you'll frequently be off by one in one or more components. Even more fun is that the green channel errors won't coincide with the red and blue errors and will be in the opposite direction, which then leads to ugliness like blacks that aren't black <em>and</em> have color to them.</p>
<p>In other words, please use 16/255 and 128/255 when those are actually where your luma and chroma values are based.</p>
<p>(I have to confess that the reason this came to mind is that I found this issue in some prototype code of mine when I started actually hacking it into shape. Needless to say, the production code doesn't have this problem.)</p>
<p>You might be thinking that it's a bit weird to be doing a conversion on 8-bit components with floating point, and you'd be correct. The place where this frequently comes up is in 3D pixel shaders. A pixel shader is a natural place to do color conversion, and is also where you'd frequently encounter 8-bit components converted to floating point. Unlike a CPU-based converter, however, there is basically no extra cost to using the correct constants. The only time you'd be better off using 0.5 in a shader instead of 128/255 is if you're on a GeForce 3, in which case (a) you're already skating on thin ice precision-wise and (b) the hardware is 9-bit signed fixed point so you're going to get 128/255 anyway. Otherwise, it's kind of sloppy to be displaying 720p video on-screen with a shader that doesn't get colors right just because someone was too lazy to type in the right constants.</p> ]]></content>
  </entry>

</feed>
